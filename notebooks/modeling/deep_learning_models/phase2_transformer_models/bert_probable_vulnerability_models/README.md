#### How to run fine-tune BERT using Pytorch 

1. Install transformers library by huggingface: https://github.com/huggingface/transformers
2. We will use the script provided to finetune on GLUE dataset by huggingface, since it's easier. You can find that as `bert_pytorch.py` in this folder.
3. Look at how to load the dataset from the `BERT-CVE Classifier` notebook. You might want to perform data cleaning on top of the loaded data before procedding to the next step. Please have a look here: https://github.com/fabric8-analytics/openshift-probable-vulnerabilities/blob/master/model_inference_triage_pipeline/run_model_inference.py#L447-L448 for that.
4. Convert the dataset to the required format for GLUE SST-2 Task: https://github.com/huggingface/transformers/blob/master/src/transformers/data/processors/glue.py#L285-L319
5. Run the `bert_pytorch.py` file using CMD by running the following command:
    ```
    python bert_pytorch.py --data_dir <your data directory; usually . i.e the current directory> --model_type bert --model_name_or_path bert-base-uncased --task_name sst-2 --output_dir <your output directory> --cache_dir <your cache dir>  --max_seq_length 512 --do_train --do_eval --do_lower_case --per_gpu_train_batch_size 12 --per_gpu_eval_batch_size 12 --learning_rate 5e-5 --weight_decay 0.01 --adam_epsilon 1e-6 --num_train_epochs 3 --save_steps 1000 --eval_all_checkpoints 
    ```
6. Run `python bert_pytorch.py --help` in case you don't understand what the above command does.